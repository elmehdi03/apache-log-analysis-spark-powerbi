# ğŸ” Web Logs Analytics & Visualization with Power BI & PostgreSQL

Ce projet propose une chaÃ®ne complÃ¨te de traitement et de visualisation de logs web. Il s'articule autour de trois axes : parsing via PySpark, stockage structurÃ© dans PostgreSQL, et dashboard interactif sous Power BI.

## ğŸ“ Structure du projet

```
â”œâ”€â”€ analyze_logs.py            # Script principal : parsing, export CSV
â”œâ”€â”€ web_logs.txt               # Fichier brut de logs Apache
â”œâ”€â”€ web_logs_postgreSQL        # Fichier brut de logs Apache
â”œâ”€â”€ Logs_Visuals.pbix          # Fichier Power BI connectÃ© Ã  PostgreSQL
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ”„ Pipeline de traitement

1. **Parsing** du fichier `web_logs.txt` avec PySpark  
2. **Export CSV** encodÃ© UTF-8 pour compatibilitÃ© avec PostgreSQL  
3. **Import dans PostgreSQL** (table `logs_web`)  
4. **Connexion directe Power BI â†” PostgreSQL**  
5. **Visualisation** dynamique (codes HTTP, heatmaps, top pagesâ€¦)

## ğŸ§  Contenu de la table PostgreSQL

```sql
CREATE TABLE logs_web (
  ip TEXT,
  timestamp TEXT,
  method TEXT,
  page TEXT,
  code INTEGER,
  date DATE,
  source TEXT DEFAULT 'from_postgres'
);
```

## ğŸ“Š Visuels Power BI inclus

- âœ… RÃ©partition des codes HTTP  
- ğŸŒ Top pages consultÃ©es  
- ğŸ§  IPs les plus actives  
- ğŸ•’ Heatmap (heure vs jour)  
- ğŸ“‰ Ã‰volution temporelle des erreurs 500  
- ğŸ§® KPI : nombre total de requÃªtes, pages uniques, IPs uniques

## ğŸš€ Instructions dâ€™utilisation

### 1. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 2. Lancer le script de parsing/export

```bash
python analyze_logs.py
```

Ce script :
- nettoie et transforme les logs
- exporte les donnÃ©es dans `outputs/logs_parsed_utf8.csv`

### 3. Importer dans PostgreSQL

Dans pgAdmin ou en ligne de commande :

```sql
\COPY logs_web FROM 'chemin_absolu/outputs/logs_parsed_utf8.csv' DELIMITER ',' CSV HEADER;
```

### 4. Ouvrir Power BI

- Lancer `Logs_Visuals.pbix`
- RafraÃ®chir la connexion (PostgreSQL requis en local)

## ğŸ§ª Export PostgreSQL (optionnel)

```sql
\COPY logs_web TO 'outputs/logs_from_postgres.csv' DELIMITER ',' CSV HEADER;
```

## âš ï¸ Distinction fichiers

- `logs_parsed_utf8.csv` â†’ Fichier gÃ©nÃ©rÃ© par Spark
- `logs_from_postgres.csv` â†’ Fichier exportÃ© depuis PostgreSQL

## ğŸ› ï¸ Commandes PostgreSQL utiles

```sql
ALTER TABLE logs_web ADD COLUMN source TEXT DEFAULT 'from_postgres';
UPDATE logs_web SET source = 'from_postgres' WHERE source IS NULL;
```

## ğŸ“Œ Ã€ venir

- [ ] Connexion directe Spark â†’ PostgreSQL  
- [ ] Cron pour automatiser lâ€™ETL  
- [ ] Power BI Service pour rafraÃ®chissement auto

## ğŸ“œ Licence

MIT License â€“ libre dâ€™utilisation et de modification.

## ğŸ¤ Contributions

Pull requests bienvenues. Projet adaptÃ© aux Ã©tudiants en data/BI et aux ingÃ©nieurs en montÃ©e de compÃ©tence.
